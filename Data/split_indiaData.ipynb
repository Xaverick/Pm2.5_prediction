{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "      <th>AQI_Bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.01</td>\n",
       "      <td>36.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>122.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>27.75</td>\n",
       "      <td>19.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>85.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>19.32</td>\n",
       "      <td>11.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>52.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "      <td>16.45</td>\n",
       "      <td>9.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "      <td>39.53</td>\n",
       "      <td>153.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "      <td>14.90</td>\n",
       "      <td>7.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "      <td>32.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City             Datetime  PM2.5  PM10    NO    NO2    NOx  NH3    CO  \\\n",
       "0  Ahmedabad  2015-01-01 01:00:00    NaN   NaN  1.00  40.01  36.37  NaN  1.00   \n",
       "1  Ahmedabad  2015-01-01 02:00:00    NaN   NaN  0.02  27.75  19.73  NaN  0.02   \n",
       "2  Ahmedabad  2015-01-01 03:00:00    NaN   NaN  0.08  19.32  11.08  NaN  0.08   \n",
       "3  Ahmedabad  2015-01-01 04:00:00    NaN   NaN  0.30  16.45   9.20  NaN  0.30   \n",
       "4  Ahmedabad  2015-01-01 05:00:00    NaN   NaN  0.12  14.90   7.85  NaN  0.12   \n",
       "\n",
       "      SO2      O3  Benzene  Toluene  Xylene  AQI AQI_Bucket  \n",
       "0  122.07     NaN      0.0      0.0     0.0  NaN        NaN  \n",
       "1   85.90     NaN      0.0      0.0     0.0  NaN        NaN  \n",
       "2   52.83     NaN      0.0      0.0     0.0  NaN        NaN  \n",
       "3   39.53  153.58      0.0      0.0     0.0  NaN        NaN  \n",
       "4   32.63     NaN      0.0      0.0     0.0  NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('city_hour.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cities: ['Ahmedabad' 'Aizawl' 'Amaravati' 'Amritsar' 'Bengaluru' 'Bhopal'\n",
      " 'Brajrajnagar' 'Chandigarh' 'Chennai' 'Coimbatore' 'Delhi' 'Ernakulam'\n",
      " 'Gurugram' 'Guwahati' 'Hyderabad' 'Jaipur' 'Jorapokhar' 'Kochi' 'Kolkata'\n",
      " 'Lucknow' 'Mumbai' 'Patna' 'Shillong' 'Talcher' 'Thiruvananthapuram'\n",
      " 'Visakhapatnam']\n"
     ]
    }
   ],
   "source": [
    "unique_cities = df['City'].unique()\n",
    "print(f\"Unique cities: {unique_cities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahmedabad: 48192 rows\n",
      "Aizawl: 2680 rows\n",
      "Amaravati: 22784 rows\n",
      "Amritsar: 29269 rows\n",
      "Bengaluru: 48192 rows\n",
      "Bhopal: 6903 rows\n",
      "Brajrajnagar: 22468 rows\n",
      "Chandigarh: 7263 rows\n",
      "Chennai: 48192 rows\n",
      "Coimbatore: 9229 rows\n",
      "Delhi: 48192 rows\n",
      "Ernakulam: 3852 rows\n",
      "Gurugram: 40258 rows\n",
      "Guwahati: 12002 rows\n",
      "Hyderabad: 48107 rows\n",
      "Jaipur: 26705 rows\n",
      "Jorapokhar: 28025 rows\n",
      "Kochi: 3854 rows\n",
      "Kolkata: 19503 rows\n",
      "Lucknow: 48192 rows\n",
      "Mumbai: 48192 rows\n",
      "Patna: 44554 rows\n",
      "Shillong: 7402 rows\n",
      "Talcher: 22161 rows\n",
      "Thiruvananthapuram: 26651 rows\n",
      "Visakhapatnam: 35053 rows\n"
     ]
    }
   ],
   "source": [
    "city_datasets = {}  # Dictionary to store city-specific datasets\n",
    "\n",
    "for city in unique_cities:\n",
    "    city_datasets[city] = df[df['City'] == city]\n",
    "    print(f\"{city}: {city_datasets[city].shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahmedabad: 48192 rows\n",
      "Aizawl_Amaravati_Amritsar: 54733 rows\n",
      "Bengaluru: 48192 rows\n",
      "Bhopal_Brajrajnagar_Chandigarh_Coimbatore: 45863 rows\n",
      "Chennai: 48192 rows\n",
      "Delhi: 48192 rows\n",
      "Gurugram: 40258 rows\n",
      "Ernakulam_Guwahati_Jaipur: 42559 rows\n",
      "Hyderabad: 48107 rows\n",
      "Jorapokhar_Kochi_Kolkata: 51382 rows\n",
      "Lucknow: 48192 rows\n",
      "Mumbai: 48192 rows\n",
      "Patna: 44554 rows\n",
      "Shillong_Visakhapatnam: 42455 rows\n",
      "Talcher_Thiruvananthapuram: 48812 rows\n"
     ]
    }
   ],
   "source": [
    "grouped_cities = {\n",
    "    'Ahmedabad': ['Ahmedabad'],\n",
    "    'Aizawl_Amaravati_Amritsar': ['Aizawl', 'Amaravati', 'Amritsar'],\n",
    "    'Bengaluru': ['Bengaluru'],\n",
    "    'Bhopal_Brajrajnagar_Chandigarh_Coimbatore': ['Bhopal', 'Brajrajnagar', 'Chandigarh', 'Coimbatore'],\n",
    "    'Chennai': ['Chennai'],\n",
    "    'Delhi': ['Delhi'],\n",
    "    'Gurugram': ['Gurugram'],\n",
    "    'Ernakulam_Guwahati_Jaipur': ['Ernakulam', 'Guwahati', 'Jaipur'],\n",
    "    'Hyderabad': ['Hyderabad'],\n",
    "    'Jorapokhar_Kochi_Kolkata': ['Jorapokhar', 'Kochi', 'Kolkata'],\n",
    "    'Lucknow': ['Lucknow'],\n",
    "    'Mumbai': ['Mumbai'],\n",
    "    'Patna': ['Patna'],\n",
    "    'Shillong_Visakhapatnam': ['Shillong', 'Visakhapatnam'],\n",
    "    'Talcher_Thiruvananthapuram': ['Talcher', 'Thiruvananthapuram']\n",
    "}\n",
    "\n",
    "# Create a dictionary to store grouped datasets\n",
    "grouped_datasets = {}\n",
    "\n",
    "# Combine datasets based on the groups\n",
    "for group_name, cities in grouped_cities.items():\n",
    "    grouped_datasets[group_name] = df[df['City'].isin(cities)]\n",
    "    print(f\"{group_name}: {grouped_datasets[group_name].shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Ahmedabad_data.csv\n",
      "Saved Aizawl_Amaravati_Amritsar_data.csv\n",
      "Saved Bengaluru_data.csv\n",
      "Saved Bhopal_Brajrajnagar_Chandigarh_Coimbatore_data.csv\n",
      "Saved Chennai_data.csv\n",
      "Saved Delhi_data.csv\n",
      "Saved Gurugram_data.csv\n",
      "Saved Ernakulam_Guwahati_Jaipur_data.csv\n",
      "Saved Hyderabad_data.csv\n",
      "Saved Jorapokhar_Kochi_Kolkata_data.csv\n",
      "Saved Lucknow_data.csv\n",
      "Saved Mumbai_data.csv\n",
      "Saved Patna_data.csv\n",
      "Saved Shillong_Visakhapatnam_data.csv\n",
      "Saved Talcher_Thiruvananthapuram_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Example: Save grouped datasets to separate CSV files (optional)\n",
    "for group_name, dataset in grouped_datasets.items():\n",
    "    dataset.to_csv(f\"{group_name}_data.csv\", index=False)\n",
    "    print(f\"Saved {group_name}_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
